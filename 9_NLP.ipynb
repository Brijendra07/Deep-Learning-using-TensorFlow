{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ef676f",
   "metadata": {
    "id": "44ef676f"
   },
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6385d6e0",
   "metadata": {
    "id": "6385d6e0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "KYEcvmsVE6g8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYEcvmsVE6g8",
    "outputId": "1219cbb6-03bf-4004-8921-0c4649dcd349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3387916d",
   "metadata": {
    "id": "3387916d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86f1c338",
   "metadata": {
    "id": "86f1c338"
   },
   "outputs": [],
   "source": [
    "path_to_file = \"shakespeare.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e465511",
   "metadata": {
    "id": "7e465511"
   },
   "outputs": [],
   "source": [
    "text = open(path_to_file,'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b43073c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b43073c5",
    "outputId": "b6c4088f-c476-45e2-9163-af8168cce963"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "031de704",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "031de704",
    "outputId": "f833a832-30e8-4c87-d2b2-61a5d4ae9041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "umbers should be broken,\n",
      "  While shadows like to thee do mock my sight?\n",
      "  Is it thy spirit that thou send'st from thee\n",
      "  So far from home into my deeds to pry,\n",
      "  To find out shames and idle hours in me,\n",
      "  The scope and tenure of thy jealousy?\n",
      "  O no, thy love though much, is not so great,\n",
      "  It is my love that keeps mine eye awake,\n",
      "  Mine own true love that doth my rest defeat,\n",
      "  To play the watchman ever for thy sake.\n",
      "    For thee watch I, whilst thou dost wake elsewhere,\n",
      "    From me far off, wi\n"
     ]
    }
   ],
   "source": [
    "print(text[40500:41000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dcc01e",
   "metadata": {
    "id": "e0dcc01e"
   },
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2811db5b",
   "metadata": {
    "id": "2811db5b"
   },
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "301e57a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "301e57a8",
    "outputId": "8520dfca-9d5c-4dbd-db13-8fb8af845a99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62df8355",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "62df8355",
    "outputId": "affa3331-ca10-444e-dbe3-82a19a994361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '\\n')\n",
      "(1, ' ')\n",
      "(2, '!')\n",
      "(3, '\"')\n",
      "(4, '&')\n",
      "(5, \"'\")\n",
      "(6, '(')\n",
      "(7, ')')\n",
      "(8, ',')\n",
      "(9, '-')\n",
      "(10, '.')\n",
      "(11, '0')\n",
      "(12, '1')\n",
      "(13, '2')\n",
      "(14, '3')\n",
      "(15, '4')\n",
      "(16, '5')\n",
      "(17, '6')\n",
      "(18, '7')\n",
      "(19, '8')\n",
      "(20, '9')\n",
      "(21, ':')\n",
      "(22, ';')\n",
      "(23, '<')\n",
      "(24, '>')\n",
      "(25, '?')\n",
      "(26, 'A')\n",
      "(27, 'B')\n",
      "(28, 'C')\n",
      "(29, 'D')\n",
      "(30, 'E')\n",
      "(31, 'F')\n",
      "(32, 'G')\n",
      "(33, 'H')\n",
      "(34, 'I')\n",
      "(35, 'J')\n",
      "(36, 'K')\n",
      "(37, 'L')\n",
      "(38, 'M')\n",
      "(39, 'N')\n",
      "(40, 'O')\n",
      "(41, 'P')\n",
      "(42, 'Q')\n",
      "(43, 'R')\n",
      "(44, 'S')\n",
      "(45, 'T')\n",
      "(46, 'U')\n",
      "(47, 'V')\n",
      "(48, 'W')\n",
      "(49, 'X')\n",
      "(50, 'Y')\n",
      "(51, 'Z')\n",
      "(52, '[')\n",
      "(53, ']')\n",
      "(54, '_')\n",
      "(55, '`')\n",
      "(56, 'a')\n",
      "(57, 'b')\n",
      "(58, 'c')\n",
      "(59, 'd')\n",
      "(60, 'e')\n",
      "(61, 'f')\n",
      "(62, 'g')\n",
      "(63, 'h')\n",
      "(64, 'i')\n",
      "(65, 'j')\n",
      "(66, 'k')\n",
      "(67, 'l')\n",
      "(68, 'm')\n",
      "(69, 'n')\n",
      "(70, 'o')\n",
      "(71, 'p')\n",
      "(72, 'q')\n",
      "(73, 'r')\n",
      "(74, 's')\n",
      "(75, 't')\n",
      "(76, 'u')\n",
      "(77, 'v')\n",
      "(78, 'w')\n",
      "(79, 'x')\n",
      "(80, 'y')\n",
      "(81, 'z')\n",
      "(82, '|')\n",
      "(83, '}')\n"
     ]
    }
   ],
   "source": [
    "for pair in enumerate(vocab):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cff8dcf",
   "metadata": {
    "id": "5cff8dcf"
   },
   "outputs": [],
   "source": [
    "char_to_ind = {char:ind for ind,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fcd6301",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fcd6301",
    "outputId": "1878124e-b33c-44dd-a4b9-12d0ff6aa67c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e46bc534",
   "metadata": {
    "id": "e46bc534"
   },
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94a2ccc7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "94a2ccc7",
    "outputId": "62a69284-f5c0-4670-e0cc-270a3d7ea1fa"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a737152",
   "metadata": {
    "id": "4a737152"
   },
   "outputs": [],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34f419ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34f419ab",
    "outputId": "102671aa-5b90-4611-e449-f7145708904a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1, ..., 30, 39, 29])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a7e3da4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1a7e3da4",
    "outputId": "eac344fd-a727-4ce9-835e-445d2c271d4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5445609,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccdb2925",
   "metadata": {
    "id": "ccdb2925"
   },
   "outputs": [],
   "source": [
    "sample = text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0614e0b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "id": "f0614e0b",
    "outputId": "2b82f8ea-5809-4d51-84a6-b39fdbcd373b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a64388b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a64388b",
    "outputId": "b9ce6f6a-eb52-4b19-e74b-b35a66f914f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
       "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
       "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
       "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
       "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
       "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
       "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
       "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
       "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
       "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
       "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
       "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
       "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
       "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
       "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
       "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
       "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
       "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
       "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
       "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
       "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
       "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
       "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
       "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
       "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
       "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
       "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
       "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
       "        1, 70, 78, 69,  1, 57, 76])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ff001",
   "metadata": {
    "id": "b94ff001"
   },
   "source": [
    "# Creating Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "614c9042",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "614c9042",
    "outputId": "81d98919-19c5-4c9b-af91-fada863c8955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ab56edc",
   "metadata": {
    "id": "8ab56edc"
   },
   "outputs": [],
   "source": [
    "line = 'From fairest creatures we desire increase'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81283c32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81283c32",
    "outputId": "b4f0e31d-fa17-468e-dd87-d54fb1fb8d59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21a43b6c",
   "metadata": {
    "id": "21a43b6c"
   },
   "outputs": [],
   "source": [
    "lines = '''\n",
    "From fairest creatures we desire increase,\n",
    "That thereby beauty's rose might never die,\n",
    "But as the riper should by time decease,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b80e85ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b80e85ea",
    "outputId": "d246033c-b8cb-4aae-90bf-c0a208bc726b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14f89ba0",
   "metadata": {
    "id": "14f89ba0"
   },
   "outputs": [],
   "source": [
    "seq_len = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f76945c8",
   "metadata": {
    "id": "f76945c8"
   },
   "outputs": [],
   "source": [
    "total_num_seq = len(text) // (seq_len + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e55e922",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7e55e922",
    "outputId": "c58dedbf-096f-400c-c201-963d1b1952f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45005"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16d9e9a4",
   "metadata": {
    "id": "16d9e9a4"
   },
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32a342d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32a342d6",
    "outputId": "a6909edf-9ab3-401f-e2ad-dba11b361ec2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.from_tensor_slices_op._TensorSliceDataset"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7e80eec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7e80eec",
    "outputId": "2674f599-4a1c-4945-81b6-693c5dae85c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "1\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "F\n",
      "r\n",
      "o\n",
      "m\n",
      " \n",
      "f\n",
      "a\n",
      "i\n",
      "r\n",
      "e\n",
      "s\n",
      "t\n",
      " \n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "t\n",
      "u\n",
      "r\n",
      "e\n",
      "s\n",
      " \n",
      "w\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "s\n",
      "i\n",
      "r\n",
      "e\n",
      " \n",
      "i\n",
      "n\n",
      "c\n",
      "r\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      "b\n",
      "y\n",
      " \n",
      "b\n",
      "e\n",
      "a\n",
      "u\n",
      "t\n",
      "y\n",
      "'\n",
      "s\n",
      " \n",
      "r\n",
      "o\n",
      "s\n",
      "e\n",
      " \n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "n\n",
      "e\n",
      "v\n",
      "e\n",
      "r\n",
      " \n",
      "d\n",
      "i\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "B\n",
      "u\n",
      "t\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "r\n",
      "i\n",
      "p\n",
      "e\n",
      "r\n",
      " \n",
      "s\n",
      "h\n",
      "o\n",
      "u\n",
      "l\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      " \n",
      "t\n",
      "i\n",
      "m\n",
      "e\n",
      " \n",
      "d\n",
      "e\n",
      "c\n",
      "e\n",
      "a\n",
      "s\n",
      "e\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "H\n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "e\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      " \n",
      "h\n",
      "e\n",
      "i\n",
      "r\n",
      " \n",
      "m\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "b\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "m\n",
      "e\n",
      "m\n",
      "o\n",
      "r\n",
      "y\n",
      ":\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "B\n",
      "u\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "o\n",
      "u\n",
      " \n",
      "c\n",
      "o\n",
      "n\n",
      "t\n",
      "r\n",
      "a\n",
      "c\n",
      "t\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "b\n",
      "r\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      " \n",
      "e\n",
      "y\n",
      "e\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "F\n",
      "e\n",
      "e\n",
      "d\n",
      "'\n",
      "s\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "l\n",
      "i\n",
      "g\n",
      "h\n",
      "t\n",
      "'\n",
      "s\n",
      " \n",
      "f\n",
      "l\n",
      "a\n",
      "m\n",
      "e\n",
      " \n",
      "w\n",
      "i\n",
      "t\n",
      "h\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      "-\n",
      "s\n",
      "u\n",
      "b\n",
      "s\n",
      "t\n",
      "a\n",
      "n\n",
      "t\n",
      "i\n",
      "a\n",
      "l\n",
      " \n",
      "f\n",
      "u\n",
      "e\n",
      "l\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "M\n",
      "a\n",
      "k\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      " \n",
      "f\n",
      "a\n",
      "m\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "w\n",
      "h\n",
      "e\n",
      "r\n",
      "e\n",
      " \n",
      "a\n",
      "b\n",
      "u\n",
      "n\n",
      "d\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "l\n",
      "i\n",
      "e\n",
      "s\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "y\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "f\n",
      "o\n",
      "e\n",
      ",\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "y\n",
      " \n",
      "s\n",
      "w\n",
      "e\n",
      "e\n",
      "t\n",
      " \n",
      "s\n",
      "e\n",
      "l\n",
      "f\n",
      " \n",
      "t\n",
      "o\n",
      "o\n",
      " \n",
      "c\n",
      "r\n",
      "u\n",
      "e\n",
      "l\n",
      ":\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "T\n",
      "h\n",
      "o\n",
      "u\n",
      " \n",
      "t\n",
      "h\n",
      "a\n",
      "t\n",
      " \n",
      "a\n",
      "r\n",
      "t\n",
      " \n",
      "n\n",
      "o\n",
      "w\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      "'\n",
      "s\n",
      " \n",
      "f\n",
      "r\n",
      "e\n",
      "s\n",
      "h\n",
      " \n",
      "o\n",
      "r\n",
      "n\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "A\n",
      "n\n",
      "d\n",
      " \n",
      "o\n",
      "n\n",
      "l\n",
      "y\n",
      " \n",
      "h\n",
      "e\n",
      "r\n",
      "a\n",
      "l\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "g\n",
      "a\n",
      "u\n",
      "d\n",
      "y\n",
      " \n",
      "s\n",
      "p\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      "\n",
      "\n",
      " \n",
      " \n",
      "W\n",
      "i\n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "n\n",
      "e\n",
      " \n",
      "o\n",
      "w\n",
      "n\n",
      " \n",
      "b\n",
      "u\n"
     ]
    }
   ],
   "source": [
    "for item in char_dataset.take(500):\n",
    "    print(ind_to_char[item.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a938954",
   "metadata": {
    "id": "0a938954"
   },
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len + 1,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "898d82f1",
   "metadata": {
    "id": "898d82f1"
   },
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1] # Hello my nam\n",
    "    target_txt = seq[1:] # ello my name\n",
    "    return input_txt,target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5e41df3",
   "metadata": {
    "id": "a5e41df3"
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93a5d264",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93a5d264",
    "outputId": "5621fbc1-d00e-4e74-bedc-aeb139815ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "\n",
      "\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    }
   ],
   "source": [
    "for input_txt,target_txt in dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[input_txt.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a6bec8b",
   "metadata": {
    "id": "3a6bec8b"
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59747969",
   "metadata": {
    "id": "59747969"
   },
   "outputs": [],
   "source": [
    "buffer_size = 10000\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c938c015",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c938c015",
    "outputId": "f8b21b68-5c0a-4d7f-d12a-a2084a55da9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ca4d3e",
   "metadata": {
    "id": "b9ca4d3e"
   },
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d10a35a9",
   "metadata": {
    "id": "d10a35a9"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01875b21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "01875b21",
    "outputId": "cb0c1386-afcd-4ad4-e650-16380f58cd4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a980a172",
   "metadata": {
    "id": "a980a172"
   },
   "outputs": [],
   "source": [
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a00277d",
   "metadata": {
    "id": "8a00277d"
   },
   "outputs": [],
   "source": [
    "rnn_neurons = 1026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3927d77c",
   "metadata": {
    "id": "3927d77c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fed506fb",
   "metadata": {
    "id": "fed506fb"
   },
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5feed2e",
   "metadata": {
    "id": "a5feed2e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,GRU,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "690bd609",
   "metadata": {
    "id": "690bd609"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
    "    model.add(GRU(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "    \n",
    "    model.add(Dense(vocab_size))\n",
    "    model.compile('adam',loss=sparse_cat_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61ac5ab0",
   "metadata": {
    "id": "61ac5ab0"
   },
   "outputs": [],
   "source": [
    "model = create_model(vocab_size,embed_dim=embed_dim,rnn_neurons=rnn_neurons,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff6488e7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff6488e7",
    "outputId": "35d0214b-b20d-4933-c6a5-64dcf96fbc03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (128, None, 64)           5376      \n",
      "                                                                 \n",
      " gru (GRU)                   (128, None, 1026)         3361176   \n",
      "                                                                 \n",
      " dense (Dense)               (128, None, 84)           86268     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f64b0de",
   "metadata": {
    "id": "4f64b0de"
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e96ebe86",
   "metadata": {
    "id": "e96ebe86"
   },
   "outputs": [],
   "source": [
    "for input_example_batch,target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "azalpjRqFWh0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "azalpjRqFWh0",
    "outputId": "f344f460-9638-4436-ce2f-6a481bfbd391"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 120, 84])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "Eb5Rcz68FaFI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eb5Rcz68FaFI",
    "outputId": "27b792e7-8599-4c56-a93e-56c5297ecf1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 84), dtype=float32, numpy=\n",
       "array([[-1.9515733e-03,  2.3139019e-03, -2.0812419e-03, ...,\n",
       "        -5.8573782e-03, -3.7908696e-03, -1.5943255e-03],\n",
       "       [ 3.7068408e-03,  5.5112923e-03,  7.8158779e-03, ...,\n",
       "        -1.4683787e-03, -4.8465845e-03,  7.7326223e-03],\n",
       "       [ 2.4731923e-04,  5.5666431e-03,  7.3474360e-04, ...,\n",
       "        -7.1350764e-03, -5.1453095e-03,  3.1248040e-03],\n",
       "       ...,\n",
       "       [-6.6426536e-04, -1.9300927e-05, -4.9441941e-03, ...,\n",
       "         7.9999724e-03, -4.3045217e-03,  3.3199941e-03],\n",
       "       [ 8.9982973e-04, -4.5494032e-03, -3.5142326e-03, ...,\n",
       "         1.1516819e-02, -5.6226244e-03, -4.9434191e-05],\n",
       "       [ 4.1756155e-03,  5.3401798e-04, -4.3175598e-03, ...,\n",
       "         1.0819666e-02, -9.0715969e-03, -4.1800332e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "HhXvA4zFFd1B",
   "metadata": {
    "id": "HhXvA4zFFd1B"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "tQRGmJbgFwxE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQRGmJbgFwxE",
    "outputId": "ca0a2e01-55eb-464e-d7ba-99d305b22ad8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
       "array([[38],\n",
       "       [81],\n",
       "       [59],\n",
       "       [54],\n",
       "       [22],\n",
       "       [39],\n",
       "       [ 4],\n",
       "       [29],\n",
       "       [49],\n",
       "       [60],\n",
       "       [45],\n",
       "       [11],\n",
       "       [49],\n",
       "       [25],\n",
       "       [57],\n",
       "       [76],\n",
       "       [ 4],\n",
       "       [76],\n",
       "       [ 5],\n",
       "       [ 3],\n",
       "       [ 2],\n",
       "       [ 7],\n",
       "       [19],\n",
       "       [ 3],\n",
       "       [ 3],\n",
       "       [43],\n",
       "       [40],\n",
       "       [12],\n",
       "       [78],\n",
       "       [ 8],\n",
       "       [49],\n",
       "       [76],\n",
       "       [66],\n",
       "       [58],\n",
       "       [63],\n",
       "       [69],\n",
       "       [75],\n",
       "       [17],\n",
       "       [11],\n",
       "       [73],\n",
       "       [63],\n",
       "       [48],\n",
       "       [60],\n",
       "       [47],\n",
       "       [62],\n",
       "       [12],\n",
       "       [81],\n",
       "       [73],\n",
       "       [73],\n",
       "       [49],\n",
       "       [11],\n",
       "       [67],\n",
       "       [76],\n",
       "       [76],\n",
       "       [10],\n",
       "       [24],\n",
       "       [26],\n",
       "       [71],\n",
       "       [19],\n",
       "       [ 3],\n",
       "       [11],\n",
       "       [81],\n",
       "       [14],\n",
       "       [33],\n",
       "       [26],\n",
       "       [36],\n",
       "       [11],\n",
       "       [ 2],\n",
       "       [68],\n",
       "       [72],\n",
       "       [ 3],\n",
       "       [20],\n",
       "       [46],\n",
       "       [29],\n",
       "       [42],\n",
       "       [24],\n",
       "       [75],\n",
       "       [ 0],\n",
       "       [21],\n",
       "       [40],\n",
       "       [34],\n",
       "       [13],\n",
       "       [66],\n",
       "       [13],\n",
       "       [74],\n",
       "       [49],\n",
       "       [55],\n",
       "       [51],\n",
       "       [48],\n",
       "       [45],\n",
       "       [74],\n",
       "       [18],\n",
       "       [63],\n",
       "       [80],\n",
       "       [21],\n",
       "       [73],\n",
       "       [ 3],\n",
       "       [43],\n",
       "       [13],\n",
       "       [67],\n",
       "       [ 9],\n",
       "       [78],\n",
       "       [51],\n",
       "       [55],\n",
       "       [57],\n",
       "       [78],\n",
       "       [69],\n",
       "       [22],\n",
       "       [11],\n",
       "       [65],\n",
       "       [45],\n",
       "       [53],\n",
       "       [43],\n",
       "       [68],\n",
       "       [83],\n",
       "       [28],\n",
       "       [43],\n",
       "       [51],\n",
       "       [11],\n",
       "       [25]])>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "yzpbVyS7Fyfo",
   "metadata": {
    "id": "yzpbVyS7Fyfo"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "jI6HfePdGBU2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jI6HfePdGBU2",
    "outputId": "dd038d71-cddd-4f60-9e3a-7c068d9dd91a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([38, 81, 59, 54, 22, 39,  4, 29, 49, 60, 45, 11, 49, 25, 57, 76,  4,\n",
       "       76,  5,  3,  2,  7, 19,  3,  3, 43, 40, 12, 78,  8, 49, 76, 66, 58,\n",
       "       63, 69, 75, 17, 11, 73, 63, 48, 60, 47, 62, 12, 81, 73, 73, 49, 11,\n",
       "       67, 76, 76, 10, 24, 26, 71, 19,  3, 11, 81, 14, 33, 26, 36, 11,  2,\n",
       "       68, 72,  3, 20, 46, 29, 42, 24, 75,  0, 21, 40, 34, 13, 66, 13, 74,\n",
       "       49, 55, 51, 48, 45, 74, 18, 63, 80, 21, 73,  3, 43, 13, 67,  9, 78,\n",
       "       51, 55, 57, 78, 69, 22, 11, 65, 45, 53, 43, 68, 83, 28, 43, 51, 11,\n",
       "       25])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "T9QUbp60GCoG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9QUbp60GCoG",
    "outputId": "4fdeb129-01f0-4865-e8b4-5daeb437ab89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'z', 'd', '_', ';', 'N', '&', 'D', 'X', 'e', 'T', '0', 'X',\n",
       "       '?', 'b', 'u', '&', 'u', \"'\", '\"', '!', ')', '8', '\"', '\"', 'R',\n",
       "       'O', '1', 'w', ',', 'X', 'u', 'k', 'c', 'h', 'n', 't', '6', '0',\n",
       "       'r', 'h', 'W', 'e', 'V', 'g', '1', 'z', 'r', 'r', 'X', '0', 'l',\n",
       "       'u', 'u', '.', '>', 'A', 'p', '8', '\"', '0', 'z', '3', 'H', 'A',\n",
       "       'K', '0', '!', 'm', 'q', '\"', '9', 'U', 'D', 'Q', '>', 't', '\\n',\n",
       "       ':', 'O', 'I', '2', 'k', '2', 's', 'X', '`', 'Z', 'W', 'T', 's',\n",
       "       '7', 'h', 'y', ':', 'r', '\"', 'R', '2', 'l', '-', 'w', 'Z', '`',\n",
       "       'b', 'w', 'n', ';', '0', 'j', 'T', ']', 'R', 'm', '}', 'C', 'R',\n",
       "       'Z', '0', '?'], dtype='<U1')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[sampled_indices] # random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7q-dCfA3GH4_",
   "metadata": {
    "id": "7q-dCfA3GH4_"
   },
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "V0WOLrEsGOlO",
   "metadata": {
    "id": "V0WOLrEsGOlO"
   },
   "outputs": [],
   "source": [
    "# model.fit(dataset,epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aTA71FbyHaWX",
   "metadata": {
    "id": "aTA71FbyHaWX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TBSTZymQKSrG",
   "metadata": {
    "id": "TBSTZymQKSrG"
   },
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "_kfqIJTnKYCa",
   "metadata": {
    "id": "_kfqIJTnKYCa"
   },
   "outputs": [],
   "source": [
    "model = create_model(vocab_size,embed_dim,rnn_neurons,batch_size=1)\n",
    "model.load_weights('shakespeare_gen.h5')\n",
    "model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "eaXRQbsGKohe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eaXRQbsGKohe",
    "outputId": "0ef73861-7851-48c7-8b81-11c84da1205b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (1, None, 64)             5376      \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (1, None, 1026)           3361176   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (1, None, 84)             86268     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "yHDks3a3K4nD",
   "metadata": {
    "id": "yHDks3a3K4nD"
   },
   "outputs": [],
   "source": [
    "def generate_text(model,start_seed,gen_size=500,temp=1.0):\n",
    "\n",
    "  num_generate = gen_size\n",
    "\n",
    "  input_eval = [char_to_ind[s] for s in start_seed]\n",
    "\n",
    "  input_eval = tf.expand_dims(input_eval,0)\n",
    "\n",
    "  text_generated = []\n",
    "\n",
    "  temperature = temp \n",
    "\n",
    "  model.reset_states()\n",
    "\n",
    "  for i in range(num_generate):\n",
    "    predictions = model(input_eval)\n",
    "    predictions = tf.squeeze(predictions,0)\n",
    "    predictions = predictions/temperature\n",
    "    predicted_id = tf.random.categorical(predictions,num_samples = 1)[-1,0].numpy()\n",
    "    input_eval = tf.expand_dims([predicted_id],0)\n",
    "    text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "  return(start_seed + \"\".join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9y_RpsTuMV6Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9y_RpsTuMV6Z",
    "outputId": "d0e270ed-6014-47b0-d656-e101a27acac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIETIXE.  PROJECT GUTENBERG ETEXT OF ILLINOIS BENEDICTINE COLLEGE\n",
      "WITH PERMISSION.  ELECTRONIC AND MACHINE READABLE COPIES MAY BE\n",
      "DISTRIBUTED SO LONG AS SUCH COPATI. We are both one, and do him nothing spring; their boots\n",
      "    Do plumed as his father shined with\n",
      "    my kinsmod?\n",
      "    I should have haded the venier to be cruel.\n",
      "  'Where be so long as that in yout his first,\n",
      "    And the gods give our King; and then into a\n",
      "    judgment.\n",
      "  FALSTAFF. I have been can be repeas'd, and here is nothing.\n",
      "  POMPEY. Sir, I love you with a most prince, Marshine her pageant comes!'\n",
      "    'Tis pity you withal.\n",
      "  IACHIMO. Fie, fie! what?\n",
      "  BALCHAS. I think without mine else. Herald! 'st we now present\n",
      "    Be of the hind'st conditions and well-favour'd faith!\n",
      "    O Roman wife, beware yourself!\n",
      "    I am no bloody, not a wife parted\n",
      "    ging that she may; 'tis not a hair may kiss any way,\n",
      "    And break friends.\n",
      "  CAMILLO. He is, sir, 'tis most humble, and to read.\n",
      "    Awake, again! away!\n",
      "  LUCIO. I will go, when \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"JULIET\",gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BOMsU8TpMgE-",
   "metadata": {
    "id": "BOMsU8TpMgE-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
